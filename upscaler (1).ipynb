{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "enTS1OgcXuSB",
        "outputId": "d027eed5-9479-4526-81c4-9c44195c8178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision==0.15.2 in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision==0.15.2) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.7.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->torchvision==0.15.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->torchvision==0.15.2) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision==0.15.2\n",
        "!pip install -q basicsr facexlib gfpgan\n",
        "!pip install -q tensorflow opencv-python torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hMOJCAGhlSdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rarfile\n",
        "!apt-get install unrar\n"
      ],
      "metadata": {
        "id": "aLX1vhxBAUCB",
        "outputId": "afaea4b8-8255-405e-da9b-d86ddcc2f0e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "import matplotlib.pyplot as plt\n",
        "from imageio import imread\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "WFuy43Nnatv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rarfile\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Path to your uploaded RAR\n",
        "rar_path = \"forcepowers.rar\"  # change to your filename\n",
        "\n",
        "# Extract RAR\n",
        "rf = rarfile.RarFile(rar_path)\n",
        "rf.extractall(\"forcepowers\")\n",
        "\n",
        "power_names = []\n",
        "\n",
        "# Walk through all Lua files and extract POWER.Name\n",
        "for root, dirs, files in os.walk(\"forcepowers\"):\n",
        "    for filename in files:\n",
        "        if filename.endswith(\".lua\"):\n",
        "            filepath = os.path.join(root, filename)\n",
        "            with open(filepath, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                content = f.read()\n",
        "                match = re.search(r'POWER\\.Name\\s*=\\s*\"([^\"]+)\"', content)\n",
        "                if match:\n",
        "                    power_names.append(match.group(1))\n",
        "\n",
        "# Remove duplicates and sort alphabetically\n",
        "power_names = sorted(set(power_names))\n",
        "\n",
        "# Show the list\n",
        "for name in power_names:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "2ddRzBcsAC-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downscale - shrinks  1/4 of its original width and height"
      ],
      "metadata": {
        "id": "7pjHujyzhJIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img= Image.open('/content/sa.jpg').convert('RGB')\n",
        "imgnp = np.array(img)\n",
        "h , w = imgnp.shape[:2]\n",
        "print(h,w)\n",
        "lowres = cv2.resize(imgnp, (w//4, h//4), interpolation=cv2.INTER_AREA)\n",
        "lowresp = Image.fromarray(lowres)\n",
        "lowresp.save('/content/lowres.png')\n",
        "from imageio import imread\n",
        "img = imread('/content/lowres.png', pilmode='L')"
      ],
      "metadata": {
        "id": "gQnlMW_1eKRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BICUBIC - Bicubic interpolation looks at a 4Ã—4 grid of surrounding pixels (16 total) and uses cubic polynomial curves instead of linear ones to estimate new pixel values. It applies 2D cubic interpolation by first interpolating in the X direction, then in the Y direction for smoother, more natural upscaling.\n",
        "\n",
        "\n",
        "If the distance is less than or equal to 1, it uses a smooth cubic curve,If the distance is between 1 and 2, it uses a different cubic equation with smaller influence.If the distance is greater than 2, the pixel has no effect (weight = 0)"
      ],
      "metadata": {
        "id": "lQyzUyNTyPgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imageio import imread\n",
        "img = imread('/content/lowres.png' )\n",
        "\n",
        "def cubic_interp(x, a=-0.5):\n",
        "    abs_x = np.abs(x)\n",
        "    abs_x2 = abs_x ** 2\n",
        "    abs_x3 = abs_x ** 3\n",
        "\n",
        "    return np.where(abs_x <= 1,\n",
        "        (a + 2) * abs_x3 - (a + 3) * abs_x2 + 1,\n",
        "        np.where(abs_x <= 2,\n",
        "            a * abs_x3 - 5 * a * abs_x2 + 8 * a * abs_x - 4 * a,\n",
        "            0))\n",
        "\n",
        "def get_pixel(img, x, y, c):\n",
        "    x = min(max(x, 0), img.shape[1] - 1)\n",
        "    y = min(max(y, 0), img.shape[0] - 1)\n",
        "    return img[y, x, c]\n",
        "\n",
        "def bicubic_resize_rgb(img, scale):\n",
        "    h, w, c = img.shape\n",
        "    new_h = int(h * scale)\n",
        "    new_w = int(w * scale)\n",
        "    output = np.zeros((new_h, new_w, c), dtype=np.float32)\n",
        "\n",
        "    for channel in range(c):\n",
        "        for i in range(new_h):\n",
        "            for j in range(new_w):\n",
        "                x = j / scale\n",
        "                y = i / scale\n",
        "                x_int = int(x)\n",
        "                y_int = int(y)\n",
        "                dx = x - x_int\n",
        "                dy = y - y_int\n",
        "\n",
        "                value = 0.0\n",
        "                for m in range(-1, 3):\n",
        "                    for n in range(-1, 3):\n",
        "                        px = get_pixel(img, x_int + n, y_int + m, channel)\n",
        "                        wx = cubic_interp(n - dx)\n",
        "                        wy = cubic_interp(m - dy)\n",
        "                        value += px * wx * wy\n",
        "\n",
        "                output[i, j, channel] = np.clip(value, 0, 255)\n",
        "\n",
        "    return output.astype(np.uint8)\n",
        "scaled = bicubic_resize_rgb(img, scale=4)\n",
        "plt.imsave('/content/bicubic.png', scaled)"
      ],
      "metadata": {
        "id": "W1tPIZVKiSyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nearest-Neighbor Interpolation - Just copies the nearest pixel value from original to new location.\n"
      ],
      "metadata": {
        "id": "ks-VgNZeMekR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = imread('/content/lowres.png')\n",
        "\n",
        "def nn_resize_rgb(img, scale):\n",
        "    h, w, c = img.shape\n",
        "    new_h = int(h * scale)\n",
        "    new_w = int(w * scale)\n",
        "    output = np.zeros((new_h, new_w, c), dtype=img.dtype)\n",
        "\n",
        "    for i in range(new_h):\n",
        "        for j in range(new_w):\n",
        "            src_x = int(j / scale)\n",
        "            src_y = int(i / scale)\n",
        "            output[i, j] = img[src_y, src_x]\n",
        "\n",
        "    return output\n",
        "\n",
        "scaled_nn = nn_resize_rgb(img, scale=4)\n",
        "\n",
        "plt.imsave('/content/nn.png', scaled_nn, cmap='gray')\n"
      ],
      "metadata": {
        "id": "PVzLWavoLoKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bilinear interpolation** looks at the 4 closest pixels around a new spot and blends their colors to fill it in. It makes the image smoother than just copying pixels, but not as sharp as more advanced methods."
      ],
      "metadata": {
        "id": "tA3A-uQEP4Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bilinear_resize_rgb(img, scale):\n",
        "    h, w, c = img.shape\n",
        "    new_h = int(h * scale)\n",
        "    new_w = int(w * scale)\n",
        "    output = np.zeros((new_h, new_w, c), dtype=np.float32)\n",
        "\n",
        "    for channel in range(c):\n",
        "        for i in range(new_h):\n",
        "            for j in range(new_w):\n",
        "                x = j / scale\n",
        "                y = i / scale\n",
        "\n",
        "                x0 = int(np.floor(x))\n",
        "                x1 = min(x0 + 1, w - 1)\n",
        "                y0 = int(np.floor(y))\n",
        "                y1 = min(y0 + 1, h - 1)\n",
        "\n",
        "                Ia = img[y0, x0, channel]\n",
        "                Ib = img[y1, x0, channel]\n",
        "                Ic = img[y0, x1, channel]\n",
        "                Id = img[y1, x1, channel]\n",
        "\n",
        "                wa = (x1 - x) * (y1 - y)\n",
        "                wb = (x1 - x) * (y - y0)\n",
        "                wc = (x - x0) * (y1 - y)\n",
        "                wd = (x - x0) * (y - y0)\n",
        "\n",
        "                output[i, j, channel] = wa * Ia + wb * Ib + wc * Ic + wd * Id\n",
        "\n",
        "    return np.clip(output, 0, 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "scaled_rgb = bilinear_resize_rgb(img, scale=4)\n",
        "plt.imsave('/content/bilinear.png', scaled_rgb)"
      ],
      "metadata": {
        "id": "9-l-fuRGNwst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REAL ESRGAN"
      ],
      "metadata": {
        "id": "c1SImP31yRdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RRDBNet(num_in_ch=3 , num_out_ch=3 ,num_feat= 64, num_block=23, num_grow_ch=32 , scale = 4)\n",
        "upscaler = RealESRGANer(\n",
        "    scale=4,\n",
        "    model_path='/content/Real-ESRGAN/weights/RealESRGAN_x4plus.pth',\n",
        "    model=model)\n",
        "sr_img_tuple = upscaler.enhance(np.array(lowresp), outscale=4)\n",
        "sr_img = sr_img_tuple[0] # Extract the image data from the tuple\n",
        "sr_img = Image.fromarray(sr_img)\n",
        "sr_img.save('/content/sr_img.png')"
      ],
      "metadata": {
        "id": "rcKyiCM3jqmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SRCNN"
      ],
      "metadata": {
        "id": "PC3VqYA3yUkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_srcnn():\n",
        "    return Sequential([\n",
        "        Conv2D(128, (9, 9), activation='relu', padding='valid', input_shape=(None, None, 1)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='valid'),\n",
        "        Conv2D(1, (5, 5), activation='linear', padding='valid')\n",
        "    ])\n",
        "\n",
        "srcnn = build_srcnn()\n",
        "\n",
        "weights_url = 'https://raw.githubusercontent.com/MarkPrecursor/SRCNN-keras/master/3051crop_weight_200.h5'\n",
        "weight_path = tf.keras.utils.get_file('3051crop_weight_200.h5', weights_url)\n",
        "srcnn.load_weights(weight_path)"
      ],
      "metadata": {
        "id": "eYMFiCWOWGi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/lowres.png', cv2.IMREAD_GRAYSCALE)\n",
        "h, w = img.shape\n",
        "bicubic_up = cv2.resize(img, (w*2, h*2), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "input_img = bicubic_up.astype(np.float32) / 255.0\n",
        "input_img = np.expand_dims(input_img, axis=(0, -1))\n",
        "pred = srcnn.predict(input_img)\n",
        "output = np.clip(pred[0, :, :, 0] * 255.0, 0, 255).astype(np.uint8)\n",
        "cv2.imwrite('/content/srcnn_upscaled.png', output)"
      ],
      "metadata": {
        "id": "uc0UT24tWMfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIMILARITY SCORE\n"
      ],
      "metadata": {
        "id": "-uaMGRdnXYY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_ssim(original_image_path, generated_image_path):\n",
        "\n",
        "    original_img = cv2.imread(original_image_path)\n",
        "    generated_img = cv2.imread(generated_image_path)\n",
        "\n",
        "\n",
        "    if original_img.shape != generated_img.shape:\n",
        "\n",
        "        generated_img = cv2.resize(generated_img, (original_img.shape[1], original_img.shape[0]))\n",
        "\n",
        "        if original_img.shape[-1] != generated_img.shape[-1]:\n",
        "             generated_img = cv2.cvtColor(generated_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "    gray_original = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
        "    gray_generated = cv2.cvtColor(generated_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "    ssim_score, _ = ssim(gray_original, gray_generated, full=True)\n",
        "\n",
        "    return ssim_score\n",
        "\n",
        "original_image_path = '/content/images.jpg'\n",
        "bicubic_image_path = '/content/bicubic.png'\n",
        "realesrgan_image_path = '/content/sr_img.png'\n",
        "\n",
        "ssim_bicubic = calculate_ssim(original_image_path, bicubic_image_path)\n",
        "ssim_realesrgan = calculate_ssim(original_image_path, realesrgan_image_path)\n",
        "\n",
        "print(f\"SSIM between original and bicubic: {ssim_bicubic:.4f}\")\n",
        "print(f\"SSIM between original and Real-ESRGAN: {ssim_realesrgan:.4f}\")\n"
      ],
      "metadata": {
        "id": "CJvWDW2HXXp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}